---
title: 'Stats 250: Lab 8'
author: "Instructional Team"
date: "Monday, June 13, 2022"
output:
  html_document:
    toc: true
    toc_float: true
    toc_collapsed: true
    theme: lumen
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Learning Objectives

### Statistical Learning Objectives
1. Visualize the relationship of two quantitative variables
1. Quantify the strength of the relationship
1. Estimate the coefficients for a simple linear regression model
1. Visualize the estimated least squares regression line
1. Strengthen understanding of hypothesis tests for the population slope

### R Learning Objectives
1. Learn how to create a scatterplot
1. Use functions to measure linear strength
1. Calculate the estimates of a simple linear regression model 
1. Visualize the estimated least squares regression line
1. Understand the regression summary output

### Functions and Syntax
1. `plot()`
1. `cor()`
1. `lm()`
1. `abline()`
1. `summary()`


***


## Lab Tutorial

### Exploring Linear Regression

We wish to study the relationship between two quantitative variables. Generally, one variable is the response variable (denoted by y) and the other variable is the explanatory variable (denoted by x). The response variable measures the outcome of the study and is also called the dependent variable. The explanatory variable is thought to explain the changes we see in the response variable and is also called the independent variable or the predictor variable. 

In this lab, we will examine relationships between two quantitative variables using a graphical tool called a scatterplot. We will interpret these scatterplots in terms of form, direction, and strength of the relationship, and use it to assess the appropriateness of using a linear regression model to describe the relationship between the two variables. If appropriate, we can perform a linear regression analysis to produce an estimated model that can be used to predict the value of the response for a given value of the predictor.  


### Data Sets

We will be utilizing two data sets throughout the lab tutorial. The first is our handy-dandy `penguins` data set.  With this data, we will focus on the relationship between flipper length (`flipper_length_mm`) and body mass (`body_mass_g`).   

```{r readPenguins}
penguins <- read.csv("penguins.csv")
```

The second data set is the `cereal` data set, which contains a random sample of 36 cereals and their nutritional information. With this data, we will focus on the relationship between sugar content (`sugar`) and calorie count (`calories`). First, read in the data.

```{r readCereal}
cereal <- read.csv("cereal.csv")
```

We can preview the data set in the following code chunk. 

```{r previewCereal}
head(cereal)
```

Note: the variables sugar and fiber are measured in grams (per serving) and the variable calories is the number of calories (per serving).


### Scatterplots

The first step in examining the relationship of two quantitative variables is to use a scatterplot to visualize the relationship. When interpreting a scatterplot, we look to comment on four key aspects:

1. **Overall Form**: does the average pattern look like a straight line or is it curved?
2. **Direction of Association**: is the relationship positive (as x increases, y increases) or negative (as x increases, y decreases)?
3. **Strength of Association**: how much do the points vary around the average pattern? (weak, moderate, or strong)
4. **Outliers**: are there any deviations from the overall form? 

To create a scatterplot in R, we can use the `plot()` function. Let's create a scatterplot for the relationship between flipper length and body mass - using flipper length as the explanatory variable (x) and body mass as the response variable (y).

```{r penguinScatterplot}
plot(body_mass_g ~ flipper_length_mm, 
     data = penguins,
     xlab = "Flipper Length (in mm)",
     ylab = "Body Mass (in g)",
     main = "Scatterplot of Body Mass vs Flipper Length")
```

In the above code, we specify the variables as **response ~ explanatory** and then specify the data set in the following argument (`data`). As always, we should include appropriate axis labels and a main title with attribution. Note: it is general convention to title a scatterplot using the format "Y versus X".

**Question:** Let's interpret the plot by commenting on the following features of the plot:

**Form:**

**Direction:** 

**Strength:**

**Outliers:**


Based on our interpretation of the plot, it would be appropriate to perform a linear regression analysis using this data.

Some examples of plots where it would *not* be appropriate to perform a linear regression analysis (without some transformations - not covered in Stats 250) are shown below.

![Non-Linear Relationships](images/badplot.jpg)

In the first plot, the relationship is being determined entirely by a few large observations. In the second plot, the variables appear to have a curved (non-linear) relationship.

**Demo #1:** Using the `cereal` data set, create a scatterplot of calorie count (`calories`) versus sugar content (`sugar`) - using calorie count as the response variable (y) and sugar content as the explanatory variable (x). 

```{r demo1, error = T}
# Replace this text with your code

```

**Question:** What comments you would make about this relationship? Would it be appropriate to perform a linear regression analysis?

**Answer:**


### Correlation

Correlation (r) measures the strength of the **linear** relationship between two variables. Correlation can take on values between -1 and 1. The sign of the correlation describes the *direction* of the linear relationship and the magnitude indicates a measure of strength. 

We can calculate the correlation between two variables using the `cor()` function.

```{r penguinCorrelation}
cor(penguins$flipper_length_mm, penguins$body_mass_g)
```

When inputting the variables into the `cor()` function, we must specify the data set with each of the variables (i.e. dataset$variable). Because of how correlation is calculated, however, the order of the variables does not matter (i.e. cor(x,y) = cor(y,x)).

```{r penguinCorrelation2}
cor(penguins$body_mass_g, penguins$flipper_length_mm)
```

We get the same value as above!

**Question:** What do you think, do the variables of flipper length and body mass have a strong *linear* relationship? Why or why not?

**Answer:** 

Do remember, however, that correlation is *discipline specific*. So a value of r = 0.8 might be a strong correlation in engineering, but a value of r = 0.6 might be considered just as strong in psychology or medical research.

**Demo #2:** Using the `cereal` data set, calculate the correlation between calorie count (`calories`) and sugar content (`sugar`). 

```{r demo2, error = T}
# Replace this text with your code

```

**Question:** How you would classify the strength of the association between the two variables? 

**Answer:** 

**Important Note**: One of the many misconceptions about regression arises from the concept of association. Scatterplots can show the association between variables, but we must remember that **correlation does not imply causation**. For example: weekly flu medication sales and weekly sweater sales for an area with extreme seasons would exhibit a positive association because both tend to go up in winter and down in summer. However, neither causes the other. The observed association between two variables is sometimes due to other factors, such as confounding variables. 


### Estimating the Equation

Since the scatterplots for the penguins data (body mass vs flipper length) and the cereal data (calorie count vs sugar content) can be summarized by straight lines, the least squares regression lines can be calculated. The least squares regression line is the line that **minimizes the sum of the squared residuals** (or the vertical distances of the data points to the line) – hence the name least squares. This fitted line can be used to describe the linear relationship between the response variable and the explanatory variable and to predict the value of the response variable for a given value of the explanatory variable. 

The linear model can be characterized by the following equation:

![](images/meanfunction.jpg){width=250px}

Where beta0 and beta1 are parameters – fixed but unknown constants. Specifically:

- beta0: is the population y-intercept 
- beta1: is the population slope

These parameters can be estimated using the least squares criterion. The resulting estimated regression line is generally written as: 

![](images/fittedvalue.jpg){width=220px}

Where b0 and b1 are referred to as the least squares *estimates* of beta0 and beta1.

To calculate the least squares estimates in R, we will use the `lm()` function. Similar to creating a scatterplot, we specify the variables as **response ~ explanatory** and then specify the data set in the following argument (`data`).

```{r penguinModel}
lm(body_mass_g ~ flipper_length_mm, data = penguins)
```

The first value (-5872.09) is the estimate of the y-intercept and the second value (50.15) is the estimate of the slope. This results in the estimated regression equation:
  
yhat = -5872.09 + 50.15x
  
**Demo #3:** Using the `cereal` data set, calculate the least squares estimates for the regression line of calorie count (`calories`) versus sugar content (`sugar`). Remember, we are using sugar content as the explanatory variable (x) and calorie count as the response variable (y).

```{r demo3, error = T}
# Replace this text with your code

```

**Question:** Which of these values represents the estimate of the y-intercept?  Which of these values represents the estimate of the slope? 

**Estimate of the y-intercept:**

**Estimate of the slope:** 


### Visualizing the Estimated Line

Instead of simply running the `lm()` function to get the estimated coefficients, we can **store the results** and pass this through other functions to extend our analysis.   

```{r peguinsModel}
lm_penguins <- lm(body_mass_g ~ flipper_length_mm, data = penguins)
```

Note: No output will be generated from this function, but you should see an object called `lm_penguins` in your Global Environment (in the top right pane of RStudio). 

To add the estimated least squares regression line to the scatterplot, we can pass the stored regression model (`lm_penguins`) through the `abline()` function. This must be done in the same code chunk *after* the `plot()` code.  

```{r penguinsPlot}
plot(body_mass_g ~ flipper_length_mm,
     data = penguins,
     xlab = "Flipper Length (in mm)",
     ylab = "Body Mass (in g)",
     main = "Scatterplot of Body Mass vs Flipper Length")

abline(lm_penguins)
```

There's nothing more to it than that. 

**Demo #4:** The regression model and scatterplot for the relationship between sugar content and calorie content have been created for you below. Add code to the chunk to include the estimated least squares regression line.

```{r cerealModel}
lm_cereal <- lm(calories ~ sugar, data = cereal)
```

```{r demo4, error = T}
plot(calories ~ sugar,
     data = cereal,
     xlab = "Sugar Content (in g)",
     ylab = "Calorie Count (in calories)",
     main = "Scatterplot of Calorie Count vs Sugar Content")

# Type your code here to add in the estimated regression line

```


### Regression Summary Output

The `lm()` function provides us with the coefficient estimates, but there is still a lot of other detailed information to unpack. We can access this additional information by passing the stored regression model through the `summary()` function. Let's try it out! 

```{r penguinsSummary}
summary(lm_penguins)
```

Woah - there's a lot going on here...


#### Coefficients Table

Let's start with the "Coefficients" table. This should look familiar to what you've seen in your lecture notes. The first row of this table represents information belonging to the estimate of the population y-intercept. Outside of the estimate (b0 = -5872.09), we are generally not interested in this row. The second row, however, represents information belonging to the estimate of the population slope. This row includes:

- the estimate of the population slope: b1 = 50.15 
- the standard error of b1: s.e.(b1) = 1.54
- the observed t-test statistic for the population slope (beta1): t = 32.56
- the *two-sided* p-value for the t-test statistic: p-value ~ 0

The value of 32.56 is the observed test statistic that tests the following hypotheses:

![](images/hypotheses.jpg){width=350px}

Note that this is a **two-sided* hypothesis test.

**Question:** Based on the data, is there support to suggest that the population slope is different than zero? Why or why not? 

**Answer:** 

Here are other ways of stating the same idea as the question above: 

- Is the explanatory variable a statistically significant *linear* predictor of the response variable? 
- Is there a statistically significant *linear* relationship between the explanatory variable and the response variable.  


#### Standard Deviation Estimate

Just below the coefficients table is the "Residual standard error". We know this as the *estimate* of the standard deviation (sigma) for the regression analysis. This is represented by "s" on the formula card. The interpretation of this value can be found below:

We would estimate that observed body masses will be about 393.3 grams away from the predicted body masses (based on the linear regression with flipper length), on average.


#### Multiple R-squared

The next row of output contains the "Multiple R-squared" value. For simple linear regression, this is equal to the square of the correlation coefficient (r^2). The interpretation for this value can be found below:

About 76.21% of the variation in body mass is explained by its linear relationship with flipper length. 

Note: We will *not* use the "Adjusted R-squared" value in this course.


#### F-test Results

The last row of output contains the "F-statistic" and its corresponding p-value. The F-test helps assess the *overall* contribution of *all* explanatory variables in the regression model. When there is only one explanatory variable in our model (like we have here), then this test is essentially doing the same thing as the t-test above. So a statistically significant test statistic here would lead us to the same conclusions as the t-test (when performing simple linear regression). 

There's a lot to digest in this output - so be sure to take some time and understand what each of the values represent. 

**Demo #5:** Using the `cereal` data set, pass the stored regression model (`lm_cereal`) through the `summary()` function.  

```{r demo5, error = T}
# Replace this text with your code

```

**Question:** Using the regression output identify the following values: 

- the estimate of the population y-intercept: 
- the estimate of the population slope:
- the standard error of b1: 
- the observed t-test statistic for the population slope: 
- the *two-sided* p-value for the t-test statistic: 
- the estimate of the standard deviation for the regression analysis: 
- the squared correlation coefficient: 


### CI for the beta1 (Optional)

In the previous section, we saw that R runs a two-sided hypothesis test for the population slope in the detailed regression summary output. What if we wanted to create a confidence interval for the population slope instead? 

To create the confidence interval for the population slope, we use the `confint()` function. For this function, we input the stored regression model (`lm_penguins`) and specify the desired confidence level. 

```{r penguinsCIslope}
confint(lm_penguins, level = 0.95)
```

The output give us two intervals - the 95% confidence interval for the population y-intercept (beta0) and the 95% confidence interval for the population slope (beta1). We are typically interested in the latter. The interpretation of this confidence interval can be found below:

We are 95% confident that the true population slope for the linear relationship between flipper length and body mass (for all penguins represented by this sample) falls between 47.1234 and 53.1831. 


***


## Try It!

Complete the following exercises. Remember, the "Try It" questions will typically be code-based and will be graded for **completeness**. Be sure to give *every* question your best shot! We strongly encourage you to form small groups and work together.

In this Try It, we will get practice with the above functions using the `coffee` data set.

Coffee cupping, or coffee tasting, is the practice of observing the tastes and aromas of brewed coffee. It is a professional practice but can be done informally by anyone or by professionals known as "Q Graders". A standard coffee cupping procedure involves deeply sniffing the coffee, then loudly slurping the coffee so it spreads to the back of the tongue. The coffee taster attempts to measure aspects of the coffee's taste, specifically the body (the texture or mouthfeel, such as oiliness), sweetness, acidity (a sharp and tangy feeling, like when biting into an orange), flavor (the characters in the cup), and aftertaste. 

The data set `coffee` contains these measured qualities (and other variables) for a random sample of 37 coffees. In the following questions, we will analyze which of these qualities has the strongest relationship with the overall rating (`rating`) - this will be the response of our analysis. The variables in the data set include:

- `rating`: the total rating (in points) on a scale of 0 - 100
- `aroma`: the aroma grade (in points) on a scale of 0 - 10
- `flavor`: the flavor grade (in points) on a scale of 0 - 10
- `aftertaste`: the aftertaste grade (in points) on a scale of 0 - 10
- `acidity`: the acidity grade (in points) on a scale of 0 - 10
- `body`: the body grade (in points) on a scale of 0 - 10
- `altitude`: the altitude (in meters) of where the coffee bean originates

> **1.** Start by reading in the data by running the code chunk below. Note: you do not have to report anything for an answer.

```{r readCoffee}
coffee <- read.csv("coffee_ratings.csv")
str(coffee)
```



> **2.** Create a scatterplot of total rating (`rating`) versus altitude (`altitude`). Remember that total rating will be the response variable throughout this analysis. Be sure to include appropriate axis labels and an appropriate title. Using the scatterplot, comment on the relationship (in terms of the overall form, the direction of the association, the strength of the association, and if there are any apparent outliers). 

```{r tryIt2, error = T}
# Replace this text with your code

```

**Answer:** Replace this text with your answer.



> **3.** Create a scatterplot of total rating (`rating`) versus body (`body`). Be sure to include appropriate axis labels and an appropriate title. Using the scatterplot, comment on the relationship (in terms of the overall form, the direction of the association, the strength of the association, and if there are any apparent outliers).   

```{r tryIt3, error = T}
# Replace this text with your code

```

**Answer:** Replace this text with your answer.



> **4.** Create a scatterplot of total rating (`rating`) versus flavor (`flavor`). Be sure to include appropriate axis labels and an appropriate title. Using the scatterplot, comment on the relationship (in terms of the overall form, the direction of the association, the strength of the association, and if there are any apparent outliers).   

```{r tryIt4, error = T}
# Replace this text with your code

```

**Answer:** Replace this text with your answer.



> **5.** Use the `cor()` function to calculate the strength of *each* linear relationship in Try It 2 - 4 (`rating` vs `altitude`, `rating` vs `body`, and `rating` vs `flavor`). Which of the explanatory variables (altitude, body, or flavor) be the best linear predictor of total rating? Hint: consider the patterns you observed in Try It 2 - 4 and the correlations computed here.

```{r tryIt5, error = T}
# Replace this text with your code

```

**Answer:** Replace this text with your answer.



> **6.** Complete the three steps (A, B, C). A. Using the `lm()` function, create and store a linear regression model (`lm_coffee`) that predicts total rating (`rating`) using flavor grade (`flavor`). B. Then, redraw the scatterplot (copy and paste your code from Try It 4) of total rating (`rating`) versus flavor grade (`flavor`). C. Finally, use the `abline()` function to add the estimated regression line to your plot. Be sure to include appropriate axis labels and an appropriate title.

```{r tryIt6A, error = T}
# Replace this text with your code

```

```{r tryIt6BandC, error = T}
# Replace this text with your code

```



> **7.** Pass your stored model (`lm_coffee`) through the `summary()` function to get the detailed regression summary output. 

```{r tryIt7, error = T}
# Replace this text with your code

```



> **8.** Using the output in Try It 7, report the value that completes the following sentence: "About ____% of the variation in total rating is explained by its linear relationship with flavor grade."

**Answer:** Replace this text with your answer.



> **9.** Using the output in Try It 7, report the value that completes the following sentence: "We would estimate that observed total ratings will be about ____ points away from the predicted total ratings (based on the linear regression with flavor grade), on average."

**Answer:** Replace this text with your answer.


***


## Dive Deeper

Complete the following questions. Remember, the "Dive Deeper" questions will involve analyzing the results and will be graded for **correctness**. If you have any questions, please ask for help (in lab, in office hours, or on Piazza)!

> **1.** In Try It 7, the test statistic and corresponding p-value for flavor grade were found to be 9.696 and 1.89e-11, respectively. In words (not notation), explain what is being assessed with these values? 

**Answer:** Replace this text with your answer.



> **2.** If someone asked you to predict the total rating for a coffee who has a flavor grade of 9.6, explain why you should be cautious to use the regression model you created in Try It 7 to do this. Some helpful numerical summaries for the explanatory variable (`flavor`) can be obtained by running the code chunk below.  

```{r diveDeeper2, error = T}
summary(coffee$flavor)
```

**Answer:** Replace this text with your answer.



***


## Submission Instructions

Carefully follow the instructions below to submit your work.

1. At the top of this document, change the `author` field to your name (in quotes!).

2. Click the **Knit** button one last time.

3.  In the Files pane (the bottom right window), check the box next to "lab08report.html".

4. Click More > Export... 

5. Leave the name of the file as "lab08report.html". **Do not change the file name.** Click Download and save the file to your computer.  

6.  On the Stats 250 Canvas site, click the "Assignments" panel on the left side of the page. Scroll to find "Lab 8", and open the assignment. Click "Start Assignment".

7.  At the bottom of the page, upload your saved "lab08report.html" file. 

8.  Click "Submit Assignment". 

